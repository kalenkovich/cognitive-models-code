{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import block_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_numbers = {\n",
    "    'A': [0, 1, 2, 3, 4, 6, 8],\n",
    "    'B': [2, 3, 4, 5, 7, 8, 9],\n",
    "    'C': [0, 1, 2, 5],\n",
    "    'D': [2, 3, 4, 5, 7, 9],\n",
    "    'E': [0, 1, 2, 5, 6],\n",
    "    'F': [0, 1, 2, 6],\n",
    "    'G': [0, 1, 2, 4, 5, 8],\n",
    "    'H': [0, 1, 3, 4, 6, 8],\n",
    "    'I': [2, 5, 7, 9],\n",
    "    'J': [0, 3, 4, 5],\n",
    "    'K': [0, 1, 6, 11, 12],\n",
    "    'L': [0, 1, 5],\n",
    "    'M': [0, 1, 3, 4, 10, 11],\n",
    "    'N': [0, 1, 3, 4, 10, 12],\n",
    "    'O': [0, 1, 2, 3, 4, 5],\n",
    "    'P': [0, 1, 2, 3, 6, 8],\n",
    "    'Q': [0, 1, 2, 3, 4, 5, 12],\n",
    "    'R': [0, 1, 2, 3, 6, 8, 12],\n",
    "    'S': [1, 2, 4, 5, 6, 8],\n",
    "    'T': [2, 7, 9],\n",
    "    'U': [0, 1, 3, 4, 5],\n",
    "    'V': [0, 1, 11, 13],\n",
    "    'W': [0, 1, 3, 4, 12, 13],\n",
    "    'X': [10, 11, 12, 13],\n",
    "    'Y': [9, 10, 11],\n",
    "    'Z': [2, 5, 11, 13]\n",
    "}\n",
    "\n",
    "feature_count = 14\n",
    "features_binary = {\n",
    "    letter: [1 if i in feature_list else 0 for i in range(feature_count)]\n",
    "    for letter, feature_list in feature_numbers.items()}\n",
    "letter_count = len(list(feature_numbers.keys()))\n",
    "alphabet = sorted(feature_numbers.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Connection(object):\n",
    "    def __init__(self, layer_from, layer_to, weights):\n",
    "        self.layer_from = layer_from\n",
    "        self.layer_to = layer_to\n",
    "        \n",
    "        # This way weights can be a constant\n",
    "        weights_shape = (layer_from.size, layer_to.size)\n",
    "        self.weights = np.ones(weights_shape) * weights\n",
    "       \n",
    "        layer_to.add_connection(self)\n",
    "    \n",
    "    def calculate_net_input(self):\n",
    "        activations_from = self.layer_from.activations\n",
    "        return (\n",
    "            (activations_from.ravel() * (activations_from.ravel() > 0) @ self.weights)\n",
    "                .reshape(self.layer_to.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self, \n",
    "                 shape, \n",
    "                 resting_activation,\n",
    "                 minimum_activation,\n",
    "                 maximum_activation,\n",
    "                 decay_rate):\n",
    "        self.shape = shape\n",
    "        self.resting_activation = resting_activation\n",
    "        self.minimum_activation = minimum_activation\n",
    "        self.maximum_activation = maximum_activation\n",
    "        self.decay_rate = decay_rate\n",
    "        self.connections = []\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "    @property\n",
    "    def size(self):\n",
    "        return self.activations.size\n",
    "        \n",
    "    def reset(self):\n",
    "        self.activations = np.ones(self.shape) * self.resting_activation\n",
    "        \n",
    "    def calculate_decay(self):\n",
    "        return (self.activations - self.resting_activation) * self.decay_rate\n",
    "    \n",
    "    def calculate_neighbours_effect(self):\n",
    "        if not self.connections:\n",
    "            return 0\n",
    "        \n",
    "        net_input = sum(\n",
    "            connection.calculate_net_input()\n",
    "            for connection in self.connections)\n",
    "        \n",
    "        return np.where(\n",
    "            net_input > 0,\n",
    "            net_input * (self.maximum_activation - self.activations),\n",
    "            net_input * (self.activations - self.minimum_activation)\n",
    "        )\n",
    "    \n",
    "    def run_cycle(self):        \n",
    "        self.activations += - self.calculate_decay() + self.calculate_neighbours_effect()\n",
    "        \n",
    "    def add_connection(self, connection: Connection):\n",
    "        self.connections.append(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLayer(Layer):\n",
    "    def present_word(self, word):\n",
    "        \"\"\"Show a word to the model\"\"\"\n",
    "        features_present = np.array([features_binary[letter] for letter in word])\n",
    "        # Set features present in the word to the maximum activation\n",
    "        self.activations = self.maximum_activation * features_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LetterLayer(Layer):\n",
    "    def print_active_letters(self):\n",
    "        for i in range(self.shape[0]):\n",
    "            active_letters = np.array(alphabet)[self.activations[i] > 0]\n",
    "            print(f'letter {i+1}: {active_letters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IAM(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Parameters\n",
    "        self.position_count = 4  # number of letters\n",
    "        \n",
    "        # Layers\n",
    "        M = 1.0  # maximum activation\n",
    "        m = -0.2  # minimum activation\n",
    "        theta = 0.07  # decay rate\n",
    "        \n",
    "        self.feature_layer = FeatureLayer(\n",
    "            shape=(self.position_count, feature_count),\n",
    "            resting_activation=0,\n",
    "            minimum_activation=m,\n",
    "            maximum_activation=M,\n",
    "            decay_rate=theta)\n",
    "        \n",
    "        self.letter_layer = LetterLayer(\n",
    "            shape=(self.position_count, letter_count),\n",
    "            resting_activation=0,\n",
    "            minimum_activation=m,\n",
    "            maximum_activation=M,\n",
    "            decay_rate=theta)\n",
    "        \n",
    "        # Connections\n",
    "        letter_to_letter_connection = Connection(\n",
    "            layer_from=self.letter_layer,\n",
    "            layer_to=self.letter_layer,\n",
    "            weights=0\n",
    "        )\n",
    "        \n",
    "        # Each feature excites letters that contain it and inhibits those that don't\n",
    "        is_excitatory = np.array([features_binary[letter] \n",
    "                                  for letter \n",
    "                                  in sorted(features_binary.keys())]).T\n",
    "        # For one letter\n",
    "        feature_to_letter_excitatory = 0.005\n",
    "        feature_to_letter_inhibitory = 0.15\n",
    "        feature_to_letter_weights_1 = np.where(\n",
    "            is_excitatory,\n",
    "            feature_to_letter_excitatory,\n",
    "            - feature_to_letter_inhibitory\n",
    "        )\n",
    "        # For all letters\n",
    "        feature_to_letter_weights = block_diag(\n",
    "            *[feature_to_letter_weights_1 for _ in range(4)])\n",
    "        feature_to_letter_connection = Connection(\n",
    "            layer_from=self.feature_layer,\n",
    "            layer_to=self.letter_layer,\n",
    "            weights=feature_to_letter_weights\n",
    "        )\n",
    "        \n",
    "    @property\n",
    "    def layers(self):\n",
    "        return (self.feature_layer, self.letter_layer)\n",
    "    \n",
    "    def reset_nodes(self):\n",
    "        for layer in self.layers:\n",
    "            layer.reset()\n",
    "        \n",
    "    def present_word(self, word: str):\n",
    "        \"\"\"Show a word to the model\"\"\"\n",
    "        self.feature_layer.present_word(word)\n",
    "    \n",
    "    def run_cycle(self):        \n",
    "        for layer in self.layers:\n",
    "            layer.run_cycle()\n",
    "        \n",
    "    def run_n_cycles(self, n: int):\n",
    "        for _ in range(n):\n",
    "            self.run_cycle()\n",
    "            \n",
    "    def print_active_letters(self):\n",
    "        self.letter_layer.print_active_letters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter 1: ['W']\n",
      "letter 2: ['O' 'Q']\n",
      "letter 3: ['R']\n",
      "letter 4: ['K']\n"
     ]
    }
   ],
   "source": [
    "iam = IAM()\n",
    "iam.present_word('WORK')\n",
    "iam.run_cycle()\n",
    "iam.print_active_letters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter 1: ['W']\n",
      "letter 2: ['Q']\n",
      "letter 3: ['R']\n",
      "letter 4: ['K']\n"
     ]
    }
   ],
   "source": [
    "iam.reset_nodes()\n",
    "iam.present_word('WQRK')\n",
    "iam.run_cycle()\n",
    "iam.print_active_letters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've copied the code to the `iam` module. Let's test the version imported from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iam import IAM as IAMTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter 1: ['W']\n",
      "letter 2: ['O' 'Q']\n",
      "letter 3: ['R']\n",
      "letter 4: ['K']\n"
     ]
    }
   ],
   "source": [
    "iam_test = IAMTest()\n",
    "iam_test.present_word('WORK')\n",
    "iam_test.run_cycle()\n",
    "iam_test.print_active_letters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_test.reset_nodes()\n",
    "iam_test.present_word('WQRK')\n",
    "iam_test.run_cycle()\n",
    "iam_test.print_active_letters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cogmod_1_IAM]",
   "language": "python",
   "name": "conda-env-cogmod_1_IAM-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
